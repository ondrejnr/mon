#!/bin/bash
set -e
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ”§ FINÃLNA OPRAVA VECTORA (endpoint + RBAC)"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

NAMESPACE="logging"

# 1. OveriÅ¥ a opraviÅ¥ ConfigMap
echo ""
echo "ğŸ“ [1/5] OPRAVA CONFIGMAP VECTORA"
# ZmaÅ¾eme starÃº ConfigMap (aj keby ju ArgoCD vracalo, urobÃ­me to teraz)
kubectl delete configmap vector-config -n $NAMESPACE --ignore-not-found

# VytvorÃ­me novÃº so sprÃ¡vnym endpointom a pridanÃ­m data_stream pre lepÅ¡iu kompatibilitu
kubectl create configmap vector-config -n $NAMESPACE --from-literal=vector.yaml="
sources:
  all_logs:
    type: kubernetes_logs
    # PridanÃ© pre znÃ­Å¾enie chÃ½b s annotÃ¡ciami (nebude sa pokÃºÅ¡aÅ¥ o node metadata)
    # Toto vyrieÅ¡i chyby s forbidden nodes
    node_annotation_fields: {}
transforms:
  simple_remap:
    type: remap
    inputs: [\"all_logs\"]
    source: |
      .pod_name = .kubernetes.pod_name
      .namespace = .kubernetes.pod_namespace
      .status = \"repaired\"
sinks:
  es_out:
    type: elasticsearch
    inputs: [\"simple_remap\"]
    endpoints: [\"http://elasticsearch.logging:9200\"]
    mode: \"bulk\"
    index: \"lamp-logs-%Y.%m.%d\"
"

echo "âœ… ConfigMap vytvorenÃ¡."

# 2. PridaÅ¥ RBAC pre Vector (ak chÃ½ba)
echo ""
echo "ğŸ”‘ [2/5] DOPLNENIE RBAC PRE VECTOR"
cat << 'RBAC' | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: vector
rules:
- apiGroups: [""]
  resources: ["pods", "namespaces", "nodes"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: vector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: vector
subjects:
- kind: ServiceAccount
  name: vector
  namespace: logging
RBAC
echo "âœ… RBAC aktualizovanÃ©."

# 3. ReÅ¡tartovaÅ¥ Vector daemonset
echo ""
echo "ğŸ”„ [3/5] REÅ TART VECTOR DAEMONSET"
kubectl rollout restart daemonset vector -n $NAMESPACE
sleep 20

# 4. Kontrola logov a endpointu
echo ""
echo "ğŸ“‹ [4/5] KONTROLA LOGOV VECTORA"
kubectl logs -n $NAMESPACE -l app=vector --tail=20 | grep -E "endpoint|endpoints|elasticsearch|http://"

# 5. Generovanie test logu a kontrola indexov
echo ""
echo "ğŸ“Š [5/5] GENEROVANIE TEST LOGOV A KONTROLA INDEXOV"
kubectl exec -n lamp deployment/apache-php -- curl -s http://localhost/ >/dev/null 2>&1 || true
sleep 10

# Zobrazenie indexov (mal by pribudnÃºÅ¥ lamp-logs-...)
kubectl exec -n $NAMESPACE deployment/elasticsearch -- curl -s "http://localhost:9200/_cat/indices?v" | grep -v "^\\."

echo ""
echo "âœ… FINÃLNA OPRAVA DOKONÄŒENÃ"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# 6. UloÅ¾enie do Gitu
cd /home/ondrejko_gulkas/mon
mkdir -p ansible/clusters/my-cluster/logging
kubectl get configmap vector-config -n $NAMESPACE -o yaml | \
  grep -v "status\|resourceVersion\|uid\|creationTimestamp\|managedFields" > \
  ansible/clusters/my-cluster/logging/vector-configmap.yaml
kubectl get clusterrole vector -o yaml | \
  grep -v "status\|resourceVersion\|uid\|creationTimestamp\|managedFields" > \
  ansible/clusters/my-cluster/logging/vector-clusterrole.yaml
kubectl get clusterrolebinding vector -o yaml | \
  grep -v "status\|resourceVersion\|uid\|creationTimestamp\|managedFields" > \
  ansible/clusters/my-cluster/logging/vector-clusterrolebinding.yaml
git add ansible/clusters/my-cluster/logging/
git commit -m "fix: vector final - correct endpoint and RBAC" || true
git push origin main || echo "âš ï¸ Git push zlyhal (moÅ¾no Å¾iadne zmeny)"
